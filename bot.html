<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice-Enabled Chatbot</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 0;
            background-color: #f5f7fa;
            color: #333;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }
        
        .header {
            background-color: #4a6baf;
            color: white;
            padding: 20px;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            flex: 1;
            display: flex;
            flex-direction: column;
        }
        
        .chat-container {
            flex: 1;
            display: flex;
            flex-direction: column;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            overflow: hidden;
            margin-bottom: 20px;
        }
        
        .chat-header {
            background-color: #4a6baf;
            color: white;
            padding: 15px;
            font-weight: bold;
        }
        
        #webchat {
            flex: 1;
            height: 500px;
            border: none;
        }
        
        .voice-controls {
            display: flex;
            justify-content: center;
            gap: 15px;
            padding: 15px;
            background-color: #f0f2f5;
            border-top: 1px solid #e1e4e8;
        }
        
        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-weight: bold;
            transition: all 0.3s;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .btn-primary {
            background-color: #4a6baf;
            color: white;
        }
        
        .btn-primary:hover {
            background-color: #3a5a9f;
        }
        
        .btn-danger {
            background-color: #e74c3c;
            color: white;
        }
        
        .btn-danger:hover {
            background-color: #c0392b;
        }
        
        .status {
            text-align: center;
            padding: 10px;
            font-style: italic;
            color: #666;
        }
        
        .footer {
            text-align: center;
            padding: 15px;
            background-color: #4a6baf;
            color: white;
            margin-top: auto;
        }
        
        @media (max-width: 768px) {
            .voice-controls {
                flex-direction: column;
                align-items: center;
            }
            
            .btn {
                width: 100%;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="header">
        <h1>Voice-Enabled Chatbot</h1>
    </div>
    
    <div class="container">
        <div class="chat-container">
            <div class="chat-header">Virtual Assistant</div>
            <iframe id="webchat" src="https://cdn.botpress.cloud/webchat/v3.2/shareable.html?configUrl=https://files.bpcontent.cloud/2025/08/12/15/20250812155352-8W8DCNAV.json"></iframe>
        </div>
        
        <div class="voice-controls">
            <button id="startListening" class="btn btn-primary">
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z"/>
                    <path d="M10 8a2 2 0 1 1-4 0V3a2 2 0 1 1 4 0v5zM8 0a3 3 0 0 0-3 3v5a3 3 0 0 0 6 0V3a3 3 0 0 0-3-3z"/>
                </svg>
                Start Listening
            </button>
            <button id="stopListening" class="btn btn-danger" disabled>
                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M5 3.5h6A1.5 1.5 0 0 1 12.5 5v6a1.5 1.5 0 0 1-1.5 1.5H5A1.5 1.5 0 0 1 3.5 11V5A1.5 1.5 0 0 1 5 3.5z"/>
                </svg>
                Stop Listening
            </button>
        </div>
        
        <div id="status" class="status">Loading chatbot...</div>
    </div>
    
    <div class="footer">
        &copy; 2023 Voice-Enabled Chatbot. All rights reserved.
    </div>

    <script>
        // Global variables
        let recognition;
        let synth = window.speechSynthesis;
        
        // Wait for the page to load
        window.addEventListener('load', function() {
            const iframe = document.getElementById('webchat');
            const statusEl = document.getElementById('status');
            const startBtn = document.getElementById('startListening');
            const stopBtn = document.getElementById('stopListening');
            
            // Initialize speech synthesis
            if (!synth) {
                statusEl.textContent = 'Text-to-speech not supported in this browser';
            }
            
            // Initialize speech recognition
            initializeSpeechRecognition();
            
            // Set up iframe message handling
            iframe.onload = function() {
                // Auto-open the chat
                setTimeout(() => {
                    iframe.contentWindow.postMessage({ type: 'show' }, '*');
                    
                    // Auto-send "hi" after a short delay to ensure chat is ready
                    setTimeout(() => {
                        iframe.contentWindow.postMessage({
                            type: 'send',
                            text: 'hi'
                        }, '*');
                        statusEl.textContent = 'Sent greeting to chatbot';
                    }, 1000);
                }, 500);
                
                // Listen for messages from the chatbot
                window.addEventListener('message', function(event) {
                    if (event.data.type === 'MESSAGE_RECEIVED') {
                        // When a message is received from the bot, speak it out
                        const botResponse = event.data.text;
                        speak(botResponse);
                        statusEl.textContent = 'Bot responded: ' + botResponse.substring(0, 50) + (botResponse.length > 50 ? '...' : '');
                    }
                });
            };
            
            // Button event listeners
            startBtn.addEventListener('click', startListening);
            stopBtn.addEventListener('click', stopListening);
            
            function initializeSpeechRecognition() {
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                
                if (!SpeechRecognition) {
                    statusEl.textContent = 'Speech recognition not supported in this browser';
                    startBtn.disabled = true;
                    return;
                }
                
                recognition = new SpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';
                
                recognition.onstart = function() {
                    statusEl.textContent = 'Listening... Speak now';
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                };
                
                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    statusEl.textContent = 'You said: ' + transcript;
                    
                    // Send the transcribed text to the chatbot
                    iframe.contentWindow.postMessage({
                        type: 'send',
                        text: transcript
                    }, '*');
                };
                
                recognition.onerror = function(event) {
                    console.error('Speech recognition error', event.error);
                    statusEl.textContent = 'Error: ' + event.error;
                    stopListening();
                };
                
                recognition.onend = function() {
                    if (!stopBtn.disabled) {
                        stopListening();
                    }
                };
            }
            
            function startListening() {
                try {
                    recognition.start();
                } catch (e) {
                    statusEl.textContent = 'Error starting speech recognition: ' + e.message;
                }
            }
            
            function stopListening() {
                try {
                    recognition.stop();
                } catch (e) {
                    console.log('Error stopping recognition:', e);
                }
                startBtn.disabled = false;
                stopBtn.disabled = true;
                statusEl.textContent = 'Ready to listen - click microphone button';
            }
            
            function speak(text) {
                if (!synth) return;
                
                // Cancel any ongoing speech
                synth.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 1.0;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;
                
                // Select a voice if available
                const voices = synth.getVoices();
                if (voices.length > 0) {
                    // Prefer a female voice if available
                    const femaleVoice = voices.find(v => v.name.includes('Female'));
                    if (femaleVoice) {
                        utterance.voice = femaleVoice;
                    } else {
                        utterance.voice = voices[0];
                    }
                }
                
                synth.speak(utterance);
            }
            
            // Load voices when they become available
            if (synth) {
                synth.onvoiceschanged = function() {
                    // Voices loaded
                };
                
                // Some browsers need this to load voices
                if (synth.getVoices().length === 0) {
                    synth.addEventListener('voiceschanged', function() {
                        // Voices loaded
                    });
                }
            }
        });
    </script>
</body>
</html>
